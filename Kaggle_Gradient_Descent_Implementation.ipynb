{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport random\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score\nfrom  matplotlib.pyplot import scatter\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-29T21:19:53.676788Z","iopub.execute_input":"2021-09-29T21:19:53.677266Z","iopub.status.idle":"2021-09-29T21:19:53.687254Z","shell.execute_reply.started":"2021-09-29T21:19:53.677229Z","shell.execute_reply":"2021-09-29T21:19:53.686633Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/students-performance-in-exams/StudentsPerformance.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:19:56.007967Z","iopub.execute_input":"2021-09-29T21:19:56.008292Z","iopub.status.idle":"2021-09-29T21:19:56.027344Z","shell.execute_reply.started":"2021-09-29T21:19:56.008270Z","shell.execute_reply":"2021-09-29T21:19:56.026416Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:19:57.718818Z","iopub.execute_input":"2021-09-29T21:19:57.719027Z","iopub.status.idle":"2021-09-29T21:19:57.728445Z","shell.execute_reply.started":"2021-09-29T21:19:57.719005Z","shell.execute_reply":"2021-09-29T21:19:57.727656Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:20:00.240994Z","iopub.execute_input":"2021-09-29T21:20:00.241222Z","iopub.status.idle":"2021-09-29T21:20:00.259898Z","shell.execute_reply.started":"2021-09-29T21:20:00.241183Z","shell.execute_reply":"2021-09-29T21:20:00.258925Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"update params of linear regression fit by hand made stochastic gradient descent","metadata":{}},{"cell_type":"code","source":"def update_weights_bias(x,y,w,b,nu):\n\t\"\"\"\n\tstochastic gradient descent for linear regression\n\t\n\tx\n\t\"\"\"\n\t# y_hat = x * w + b\n\ty_hat = sum([X * W for (X,W) in zip(x,w)]) + b\n\tdiff = y_hat - y\n\tw2 = []\n\t# update weights\n\tfor i in range(len(x)):\n\t\tw2.append(w[i] - (nu * 2 * x[i] * diff))\n\t# update bias\n\tb2 = b - (nu * 2* diff)\n\tprint(\"diff:\", diff)\n\tprint(\"weight: \", w2)\n\tprint(\"bias: \", b2)\n\treturn (w2, b2)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:20:02.269696Z","iopub.execute_input":"2021-09-29T21:20:02.270194Z","iopub.status.idle":"2021-09-29T21:20:02.276580Z","shell.execute_reply.started":"2021-09-29T21:20:02.270168Z","shell.execute_reply":"2021-09-29T21:20:02.275559Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def plus_or_minus(n):\n    \"\"\" returns a random floating point number between -n and n\"\"\"\n    return random.random() * 2 * n - n","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:21:05.496222Z","iopub.execute_input":"2021-09-29T21:21:05.496429Z","iopub.status.idle":"2021-09-29T21:21:05.499889Z","shell.execute_reply.started":"2021-09-29T21:21:05.496408Z","shell.execute_reply":"2021-09-29T21:21:05.499181Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"b = 0\nw = [plus_or_minus(1), plus_or_minus(1)]","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:21:21.545908Z","iopub.execute_input":"2021-09-29T21:21:21.546370Z","iopub.status.idle":"2021-09-29T21:21:21.550299Z","shell.execute_reply.started":"2021-09-29T21:21:21.546335Z","shell.execute_reply":"2021-09-29T21:21:21.549707Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y = df.pop(\"reading score\")\nX = df.loc[:, [\"writing score\", \"math score\"]]","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:21:37.958269Z","iopub.execute_input":"2021-09-29T21:21:37.958889Z","iopub.status.idle":"2021-09-29T21:21:38.071520Z","shell.execute_reply.started":"2021-09-29T21:21:37.958861Z","shell.execute_reply":"2021-09-29T21:21:38.070162Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:21:53.608855Z","iopub.execute_input":"2021-09-29T21:21:53.609287Z","iopub.status.idle":"2021-09-29T21:21:53.614532Z","shell.execute_reply.started":"2021-09-29T21:21:53.609265Z","shell.execute_reply":"2021-09-29T21:21:53.613632Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:21:55.057031Z","iopub.execute_input":"2021-09-29T21:21:55.058276Z","iopub.status.idle":"2021-09-29T21:21:55.063325Z","shell.execute_reply.started":"2021-09-29T21:21:55.058247Z","shell.execute_reply":"2021-09-29T21:21:55.062559Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def ols_gradient_descent(x, y, w, b, nu):\n    \"\"\" iterates through the dataset updating weights and bias (slopes and intercept) of linear regression model.\n    Has print statements to show what is happening during run.\"\"\"\n    for i in range(len(y)):\n        print(\"X:\", x.iloc[i,:])\n        print(\"y:\", y.iloc[i])\n        print(\"weights:\", w)\n        print(\"bias:\", b)\n        w, b = update_weights_bias(x.iloc[i, :] , y.iloc[i],w, b, nu)\n        print('==========')\n    return (w,b)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:26:02.982979Z","iopub.execute_input":"2021-09-29T21:26:02.983253Z","iopub.status.idle":"2021-09-29T21:26:02.988917Z","shell.execute_reply.started":"2021-09-29T21:26:02.983225Z","shell.execute_reply":"2021-09-29T21:26:02.988146Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\nscatter(X.iloc[:,1], y)\nscatter(X.iloc[:,0], y)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:26:09.728572Z","iopub.execute_input":"2021-09-29T21:26:09.728853Z","iopub.status.idle":"2021-09-29T21:26:09.920596Z","shell.execute_reply.started":"2021-09-29T21:26:09.728824Z","shell.execute_reply":"2021-09-29T21:26:09.920219Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"scatter(X.iloc[:,1], X.iloc[:,0])","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:27:24.232182Z","iopub.execute_input":"2021-09-29T21:27:24.232553Z","iopub.status.idle":"2021-09-29T21:27:24.384958Z","shell.execute_reply.started":"2021-09-29T21:27:24.232532Z","shell.execute_reply":"2021-09-29T21:27:24.384145Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"very clear linear relationship. There's some variance, but clearly doing well in one subject means doing well in another. ","metadata":{}},{"cell_type":"markdown","source":"fitting simple linear regressions","metadata":{}},{"cell_type":"code","source":"np.polyfit(X.iloc[:,1], y, 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:13:10.237249Z","iopub.execute_input":"2021-09-29T19:13:10.237553Z","iopub.status.idle":"2021-09-29T19:13:10.247908Z","shell.execute_reply.started":"2021-09-29T19:13:10.237513Z","shell.execute_reply":"2021-09-29T19:13:10.246839Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"np.polyfit(X.iloc[:,0], y, 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:13:10.249879Z","iopub.execute_input":"2021-09-29T19:13:10.250198Z","iopub.status.idle":"2021-09-29T19:13:10.258096Z","shell.execute_reply.started":"2021-09-29T19:13:10.250159Z","shell.execute_reply":"2021-09-29T19:13:10.257502Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Fitting a multiple linear regression","metadata":{}},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:59:04.044314Z","iopub.execute_input":"2021-09-29T21:59:04.044533Z","iopub.status.idle":"2021-09-29T21:59:04.052385Z","shell.execute_reply.started":"2021-09-29T21:59:04.044511Z","shell.execute_reply":"2021-09-29T21:59:04.051524Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = linear_model.LinearRegression() \nmodel.fit(X, y)\nprint(X.columns)\n# print(model.feature_names_in_)feature_names_in_\nprint(\"weights: \", model.coef_)\nprint(\"bias: \", model.intercept_)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T22:00:19.232611Z","iopub.execute_input":"2021-09-29T22:00:19.232855Z","iopub.status.idle":"2021-09-29T22:00:19.243172Z","shell.execute_reply.started":"2021-09-29T22:00:19.232827Z","shell.execute_reply":"2021-09-29T22:00:19.242036Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"r2_score(y, model.predict(X))","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:13:10.278233Z","iopub.execute_input":"2021-09-29T19:13:10.278550Z","iopub.status.idle":"2021-09-29T19:13:10.286881Z","shell.execute_reply.started":"2021-09-29T19:13:10.278508Z","shell.execute_reply":"2021-09-29T19:13:10.286278Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model2 = linear_model.LinearRegression() \nmodel2.fit(X.iloc[:,:1], y)\nprint(\"weights: \", model2.coef_)\nprint(\"bias: \", model2.intercept_)\nprint(r2_score(y, model2.predict(X.iloc[:, :1])))","metadata":{"execution":{"iopub.status.busy":"2021-09-29T22:01:22.173030Z","iopub.execute_input":"2021-09-29T22:01:22.173488Z","iopub.status.idle":"2021-09-29T22:01:22.187813Z","shell.execute_reply.started":"2021-09-29T22:01:22.173460Z","shell.execute_reply":"2021-09-29T22:01:22.187074Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"very high r squared. Dropping a varible leaves it almost entirely unchanged. Means the variables are extremely linearly correlated.","metadata":{}},{"cell_type":"code","source":"scatter(X.iloc[:,0], X.iloc[:,1])","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:13:10.307652Z","iopub.execute_input":"2021-09-29T19:13:10.307898Z","iopub.status.idle":"2021-09-29T19:13:10.480332Z","shell.execute_reply.started":"2021-09-29T19:13:10.307868Z","shell.execute_reply":"2021-09-29T19:13:10.479428Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"gradient descent is very particular with the learning rate but it handles highly correlated variables just fine. ","metadata":{}},{"cell_type":"code","source":"w, b = ols_gradient_descent(X, y, w, b, 0.00001)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:13:10.481799Z","iopub.execute_input":"2021-09-29T19:13:10.482151Z","iopub.status.idle":"2021-09-29T19:13:12.828737Z","shell.execute_reply.started":"2021-09-29T19:13:10.482109Z","shell.execute_reply":"2021-09-29T19:13:12.827901Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"b = 0\nw = [plus_or_minus(1)]\nw, b = ols_gradient_descent(X.iloc[:, :1], y, w, b, 0.00001)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:14:42.283985Z","iopub.execute_input":"2021-09-29T19:14:42.284691Z","iopub.status.idle":"2021-09-29T19:14:44.347606Z","shell.execute_reply.started":"2021-09-29T19:14:42.284643Z","shell.execute_reply":"2021-09-29T19:14:44.346797Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}